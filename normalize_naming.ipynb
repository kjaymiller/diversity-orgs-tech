{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('updated_diversity_orgs.json').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-burst",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df[['name','city']]:\n",
    "    df[col] = df[col].str.strip()\n",
    "    print('Number of unique values in ' + str(col) +': ' + str(df[col].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows where duplicates may exist\n",
    "def replacements(df=df):\n",
    "    \"\"\"generate a list of unique values group them based on similarity\"\"\"\n",
    "    unique_city = df['city'].unique().tolist()\n",
    "    score_sort = [(x,) + i\n",
    "                 for x in unique_city \n",
    "                 for i in process.extract(x, unique_city, scorer=fuzz.token_sort_ratio)]\n",
    "    #Create a dataframe from the tuples\n",
    "    similarity_sort = pd.DataFrame(score_sort, columns=['city_sort','match_sort','score_sort'])\n",
    "    return similarity_sort[similarity_sort['score_sort'].between(80, 99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = replacements().groupby(by=['match_sort'])\n",
    "groups.count()[groups.count()['city_sort'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the List and Check Against a City\n",
    "city = 'New York'\n",
    "unique_list = replacements()\n",
    "unique_list[unique_list['match_sort'].str.contains(city)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify(df, match_series, city_sort_value):\n",
    "    \"\"\"\n",
    "    given a dataframe(df) and match_series,\n",
    "    set all values of the dataframe to the city_sort_value\n",
    "    \"\"\"\n",
    "    matcher = match_series[match_series['match_sort'] == city_sort_value]['city_sort']\n",
    "    df.loc[df['city'].isin(matcher), ['city']] = city_sort_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\n",
    "    'Washington, DC',\n",
    "    'Atlanta, GA',\n",
    "    'Austin, TX',\n",
    "    'Boston, MA',\n",
    "    'Los Angeles, CA'\n",
    "    'Houston, TX',\n",
    "    'Cleveland, OH',\n",
    "    'San Diego, CA',\n",
    "    'Dallas, TX',\n",
    "    'Portland, OR',\n",
    "    'Raleigh-Durham, NC',\n",
    "    'San Francisco, CA',\n",
    "    'Seattle, WA',\n",
    "    'Rio De Janeiro, Brazil',\n",
    "    'London, UK',\n",
    "    'Twin Cities, USA',\n",
    "    'SÃ£o Paulo, Brazil',\n",
    "    'Tel Aviv, Israel',\n",
    "    'New York City, NY'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a value to match against and change all found values to that assigned value\n",
    "for city in cities:\n",
    "    unify(df, unique_list, city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Make a Brute Force change\n",
    "df.loc[df['city'].str.contains('London'), ['city']] = \"London, United Kingdom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check a value in the DF\n",
    "df[df['city'].str.contains(\"London\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Work\n",
    "df.to_json('updated_diversity_orgs.json', orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
